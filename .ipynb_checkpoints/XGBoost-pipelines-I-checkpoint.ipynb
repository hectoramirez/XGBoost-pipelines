{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost in a pipeline using the Ames Housing dataset\n",
    "\n",
    "by Héctor Ramírez\n",
    "<hr>\n",
    "\n",
    "Throughout this example, we will be working with the Ames Housing prices dataset introdced in http://jse.amstat.org/v19n3/decock.pdf. As the abstaract states: \"[...] a data set describing the sale of individual residential property in Ames, Iowa from 2006 to 2010. The data set contains observations and a large number of explanatory variables involved in assessing home values.\".\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings; warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 21 columns):\n",
      "MSSubClass      1460 non-null int64\n",
      "MSZoning        1460 non-null object\n",
      "LotFrontage     1201 non-null float64\n",
      "LotArea         1460 non-null int64\n",
      "Neighborhood    1460 non-null object\n",
      "BldgType        1460 non-null object\n",
      "HouseStyle      1460 non-null object\n",
      "OverallQual     1460 non-null int64\n",
      "OverallCond     1460 non-null int64\n",
      "YearBuilt       1460 non-null int64\n",
      "Remodeled       1460 non-null int64\n",
      "GrLivArea       1460 non-null int64\n",
      "BsmtFullBath    1460 non-null int64\n",
      "BsmtHalfBath    1460 non-null int64\n",
      "FullBath        1460 non-null int64\n",
      "HalfBath        1460 non-null int64\n",
      "BedroomAbvGr    1460 non-null int64\n",
      "Fireplaces      1460 non-null int64\n",
      "GarageArea      1460 non-null int64\n",
      "PavedDrive      1460 non-null object\n",
      "SalePrice       1460 non-null int64\n",
      "dtypes: float64(1), int64(15), object(5)\n",
      "memory usage: 239.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ames_housing_data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Preprocessing data\n",
    "\n",
    "To use this dataset to train a model and use it into a pipeline, we need to do some preprocessing in advance. First, missing values need to be filled in in the LotFrontage column. Then, categorical columns (those of object type) need to be transformed to numeric, encoded values.\n",
    "\n",
    "We follow two different approaches: LabelEncoder + OneHotEncoder and DictVectorizer.\n",
    "\n",
    "### Encoding categorical columns I: LabelEncoder + OneHotEncoder\n",
    "\n",
    "First, we will need to fill in missing values. Then, we will need to encode any categorical columns in the dataset using one-hot encoding so that they are encoded numerically.\n",
    "\n",
    "The data has five categorical columns: MSZoning, PavedDrive, Neighborhood, BldgType, and HouseStyle. Scikit-learn has a LabelEncoder function that converts the values in each categorical column into integers.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MSZoning Neighborhood BldgType HouseStyle PavedDrive\n",
      "0       RL      CollgCr     1Fam     2Story          Y\n",
      "1       RL      Veenker     1Fam     1Story          Y\n",
      "2       RL      CollgCr     1Fam     2Story          Y\n",
      "3       RL      Crawfor     1Fam     2Story          Y\n",
      "4       RL      NoRidge     1Fam     2Story          Y\n",
      "   MSZoning  Neighborhood  BldgType  HouseStyle  PavedDrive\n",
      "0         3             5         0           5           2\n",
      "1         3            24         0           2           2\n",
      "2         3             5         0           5           2\n",
      "3         3             6         0           5           2\n",
      "4         3            15         0           5           2\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with 0\n",
    "df.LotFrontage = df.LotFrontage.fillna(0)\n",
    "\n",
    "# Create a boolean mask for categorical columns and get list of categorical column names\n",
    "categorical_mask = (df.dtypes == object)\n",
    "categorical_columns = df.columns[categorical_mask].tolist()\n",
    "\n",
    "print(df[categorical_columns].head())\n",
    "\n",
    "# Create LabelEncoder object and apply LabelEncoder to categorical columns\n",
    "le = LabelEncoder()\n",
    "df[categorical_columns] = df[categorical_columns].apply(lambda x: le.fit_transform(x))\n",
    "\n",
    "print(df[categorical_columns].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "There is no natural ordering between the entries yet. As an example: Using LabelEncoder, the CollgCr Neighborhood was encoded as 5, while the Veenker Neighborhood was encoded as 24, and Crawfor as 6. Is Veenker \"greater\" than Crawfor and CollgCr? No - and allowing the model to assume this natural ordering may result in poor performance.\n",
    "<br><br>\n",
    "As a result, there is another step needed: We have to apply a one-hot encoding to create binary, or \"dummy\" variables. You can do this using scikit-learn's OneHotEncoder.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 1.000e+00 6.000e+01 6.500e+01 8.450e+03\n",
      "  7.000e+00 5.000e+00 2.003e+03 0.000e+00 1.710e+03 1.000e+00 0.000e+00\n",
      "  2.000e+00 1.000e+00 3.000e+00 0.000e+00 5.480e+02 2.085e+05]\n",
      " [0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 1.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 1.000e+00 2.000e+01 8.000e+01 9.600e+03\n",
      "  6.000e+00 8.000e+00 1.976e+03 0.000e+00 1.262e+03 0.000e+00 1.000e+00\n",
      "  2.000e+00 0.000e+00 3.000e+00 1.000e+00 4.600e+02 1.815e+05]\n",
      " [0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 1.000e+00 6.000e+01 6.800e+01 1.125e+04\n",
      "  7.000e+00 5.000e+00 2.001e+03 1.000e+00 1.786e+03 1.000e+00 0.000e+00\n",
      "  2.000e+00 1.000e+00 3.000e+00 1.000e+00 6.080e+02 2.235e+05]\n",
      " [0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 1.000e+00 7.000e+01 6.000e+01 9.550e+03\n",
      "  7.000e+00 5.000e+00 1.915e+03 1.000e+00 1.717e+03 1.000e+00 0.000e+00\n",
      "  1.000e+00 0.000e+00 3.000e+00 1.000e+00 6.420e+02 1.400e+05]\n",
      " [0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.000e+00 0.000e+00\n",
      "  0.000e+00 0.000e+00 0.000e+00 1.000e+00 6.000e+01 8.400e+01 1.426e+04\n",
      "  8.000e+00 5.000e+00 2.000e+03 0.000e+00 2.198e+03 1.000e+00 0.000e+00\n",
      "  2.000e+00 1.000e+00 4.000e+00 1.000e+00 8.360e+02 2.500e+05]]\n",
      "(1460, 21)\n",
      "(1460, 62)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hramirez/Library/Python/3.7/lib/python/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create OneHotEncoder and apply it to categorical columns\n",
    "ohe = OneHotEncoder(categorical_features=categorical_mask, sparse=False)\n",
    "df_encoded = ohe.fit_transform(df)\n",
    "\n",
    "print(df_encoded[:5, :])\n",
    "print(df.shape)\n",
    "print(df_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "After one hot encoding, which creates binary variables out of the categorical variables, there are now 62 columns. Furthermore, notice that df_encoded is no longer a dataframe.\n",
    "\n",
    "### Encoding categorical columns I: DictVectorizer\n",
    "\n",
    "The two step process you just went through - LabelEncoder followed by OneHotEncoder - can be simplified by using a DictVectorizer.\n",
    "\n",
    "Using a DictVectorizer on a DataFrame that has been converted to a dictionary allows us to get label encoding as well as one-hot encoding in one go.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 2.000e+00 5.480e+02\n",
      "  1.710e+03 1.000e+00 5.000e+00 8.450e+03 6.500e+01 6.000e+01 3.000e+00\n",
      "  5.000e+00 5.000e+00 7.000e+00 2.000e+00 0.000e+00 2.085e+05 2.003e+03]\n",
      " [3.000e+00 0.000e+00 0.000e+00 1.000e+00 1.000e+00 2.000e+00 4.600e+02\n",
      "  1.262e+03 0.000e+00 2.000e+00 9.600e+03 8.000e+01 2.000e+01 3.000e+00\n",
      "  2.400e+01 8.000e+00 6.000e+00 2.000e+00 0.000e+00 1.815e+05 1.976e+03]\n",
      " [3.000e+00 0.000e+00 1.000e+00 0.000e+00 1.000e+00 2.000e+00 6.080e+02\n",
      "  1.786e+03 1.000e+00 5.000e+00 1.125e+04 6.800e+01 6.000e+01 3.000e+00\n",
      "  5.000e+00 5.000e+00 7.000e+00 2.000e+00 1.000e+00 2.235e+05 2.001e+03]\n",
      " [3.000e+00 0.000e+00 1.000e+00 0.000e+00 1.000e+00 1.000e+00 6.420e+02\n",
      "  1.717e+03 0.000e+00 5.000e+00 9.550e+03 6.000e+01 7.000e+01 3.000e+00\n",
      "  6.000e+00 5.000e+00 7.000e+00 2.000e+00 1.000e+00 1.400e+05 1.915e+03]\n",
      " [4.000e+00 0.000e+00 1.000e+00 0.000e+00 1.000e+00 2.000e+00 8.360e+02\n",
      "  2.198e+03 1.000e+00 5.000e+00 1.426e+04 8.400e+01 6.000e+01 3.000e+00\n",
      "  1.500e+01 5.000e+00 8.000e+00 2.000e+00 0.000e+00 2.500e+05 2.000e+03]]\n",
      "{'MSSubClass': 12, 'MSZoning': 13, 'LotFrontage': 11, 'LotArea': 10, 'Neighborhood': 14, 'BldgType': 1, 'HouseStyle': 9, 'OverallQual': 16, 'OverallCond': 15, 'YearBuilt': 20, 'Remodeled': 18, 'GrLivArea': 7, 'BsmtFullBath': 2, 'BsmtHalfBath': 3, 'FullBath': 5, 'HalfBath': 8, 'BedroomAbvGr': 0, 'Fireplaces': 4, 'GarageArea': 6, 'PavedDrive': 17, 'SalePrice': 19}\n"
     ]
    }
   ],
   "source": [
    "# Convert df into a dictionary, create the DictVectorizer object and apply it on df\n",
    "df_dict = df.to_dict('records')\n",
    "dv = DictVectorizer(sparse=False)\n",
    "df_encoded = dv.fit_transform(df_dict)\n",
    "\n",
    "print(df_encoded[:5,:])\n",
    "print(dv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Besides simplifying the process into one step, DictVectorizer has useful attributes such as vocabulary_ which maps the names of the features to their indices.\n",
    "\n",
    "### Preprocessing within a pipeline\n",
    "\n",
    "We will use the much cleaner and more succinct DictVectorizer approach and put it alongside an XGBoostRegressor inside of a scikit-learn pipeline: first using fit/predict methods, and then cross validation.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:34:59] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "RMSE: 19008.073730\n"
     ]
    }
   ],
   "source": [
    "# Fill LotFrontage missing values with 0\n",
    "df.LotFrontage = df.LotFrontage.fillna(0)\n",
    "\n",
    "# Setup the pipeline steps, create and fit the pipeline\n",
    "steps = [(\"ohe_onestep\", DictVectorizer(sparse=False)),\n",
    "         (\"xgb_model\", xgb.XGBRegressor())]\n",
    "\n",
    "xgb_pipeline = Pipeline(steps)\n",
    "\n",
    "xgb_pipeline.fit(df.iloc[:,:-1].to_dict('records'), df.SalePrice)\n",
    "preds = xgb_pipeline.predict(df.iloc[:,:-1].to_dict('records'))\n",
    "rmse = np.sqrt(mean_squared_error(df.SalePrice, preds))\n",
    "print(\"\\nRMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:34:59] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:34:59] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:34:59] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:00] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:00] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:00] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:00] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:00] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:01] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:35:01] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "10-fold RMSE:  28440.796697477967\n"
     ]
    }
   ],
   "source": [
    "cross_val_scores = cross_val_score(xgb_pipeline, df.iloc[:,:-1].to_dict('records'), df.SalePrice\n",
    "                                   , cv=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "print(\"\\n10-fold RMSE: \", np.mean(np.sqrt(np.abs(cross_val_scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
